{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0b06ba3f-3c98-4fd7-948d-362d3260fc5d",
   "metadata": {},
   "source": [
    "# Введение в NLP, часть 2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0f3154e",
   "metadata": {},
   "source": [
    "## NER c BERT (25 баллов)\n",
    "\n",
    "В данном задании мы будем обучать BERT на задаче Named Entity Recognition."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27a696ec-f1af-4779-bb81-a4aa644fddfd",
   "metadata": {},
   "source": [
    "### Подготовка данных (5 баллов)\n",
    "\n",
    "Подумать о:\n",
    "1. Как subword токенизация повлияет на BIO раззметку?\n",
    "2. Что делать с `[CLS]` и `[SEP]` токенами? (Проверьте что использует `DataCollatorForTokenClassification`)\n",
    "\n",
    "> Hint! Токенайзер умеет работать с предразделёнными на «слова» текстами"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "066c1544-367c-492b-b7be-4e886babfc5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from datasets import load_dataset\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "\n",
    "BASE_NER_MODEL = \"bert-base-cased\"\n",
    "bert_tokenizer = AutoTokenizer.from_pretrained(BASE_NER_MODEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d13c09d0-a7ab-4fe3-aac4-fb8ba4b5f1f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['id', 'tokens', 'pos_tags', 'chunk_tags', 'ner_tags'],\n",
       "        num_rows: 14041\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['id', 'tokens', 'pos_tags', 'chunk_tags', 'ner_tags'],\n",
       "        num_rows: 3250\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['id', 'tokens', 'pos_tags', 'chunk_tags', 'ner_tags'],\n",
       "        num_rows: 3453\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conll2003 = load_dataset(\"eriktks/conll2003\", trust_remote_code=True)\n",
    "conll2003"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "92a1ac5b-0722-4387-a885-80b927fbc10a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': '100',\n",
       " 'tokens': ['Rabinovich',\n",
       "  'is',\n",
       "  'winding',\n",
       "  'up',\n",
       "  'his',\n",
       "  'term',\n",
       "  'as',\n",
       "  'ambassador',\n",
       "  '.'],\n",
       " 'pos_tags': [21, 42, 39, 33, 29, 21, 15, 21, 7],\n",
       " 'chunk_tags': [11, 21, 22, 15, 11, 12, 13, 11, 0],\n",
       " 'ner_tags': [1, 0, 0, 0, 0, 0, 0, 0, 0]}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example = conll2003[\"train\"][100]\n",
    "example"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "573be60b-3c59-4a4c-9cc7-2cab8d9f2a2d",
   "metadata": {},
   "source": [
    "* tokens - исходные токены, для которых была сделана NER-разметка\n",
    "* ner_tags - векторизированные метки NER-тэгов\n",
    "* pos_tags - разметка частей речи, которую мы игнорируем\n",
    "* chunk_tags - разметка чанков, которую мы игнорируем\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c070226-e70f-4df1-b770-f403a19ef205",
   "metadata": {},
   "source": [
    "Обратите внимание, что количество токенов может превышать количество исходных лейблов:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d1f4628f-7e0f-4113-ac0a-04f81f77271c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['[CLS]',\n",
       " 'Ra',\n",
       " '##bino',\n",
       " '##vich',\n",
       " 'is',\n",
       " 'winding',\n",
       " 'up',\n",
       " 'his',\n",
       " 'term',\n",
       " 'as',\n",
       " 'ambassador',\n",
       " '.',\n",
       " '[SEP]']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bert_tokenizer(example[\"tokens\"], is_split_into_words=True).tokens()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdb99e70-85e2-438f-8c68-e15a6701ccfa",
   "metadata": {},
   "source": [
    "Значение тэга в `ner_tags` отображается в метку NER:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1b8fce68-13e8-4093-a147-15ae865ac73a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NER TAGS [1, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "ClassLabel(names=['O', 'B-PER', 'I-PER', 'B-ORG', 'I-ORG', 'B-LOC', 'I-LOC', 'B-MISC', 'I-MISC'], id=None)\n"
     ]
    }
   ],
   "source": [
    "print(\"NER TAGS\", example[\"ner_tags\"])\n",
    "print(conll2003[\"train\"].features[\"ner_tags\"].feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "27a3addb-073d-4a2f-bd49-caa3411a4369",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Оригинальные токены\n",
      "['Rabinovich', 'is', 'winding', 'up', 'his', 'term', 'as', 'ambassador', '.']\n",
      "Векторизированные NER метки токенов\n",
      "[1, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Текстовые NER метки токенов\n",
      "['B-PER', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Токены после работы токенайзера BERT\n",
      "['[CLS]', 'Ra', '##bino', '##vich', 'is', 'winding', 'up', 'his', 'term', 'as', 'ambassador', '.', '[SEP]']\n"
     ]
    }
   ],
   "source": [
    "print(\"Оригинальные токены\")\n",
    "print(example[\"tokens\"])\n",
    "print(\"Векторизированные NER метки токенов\")\n",
    "print(example[\"ner_tags\"])\n",
    "tags_str = []\n",
    "features = conll2003[\"train\"].features[\"ner_tags\"].feature\n",
    "\n",
    "for tag in example[\"ner_tags\"]:\n",
    "    tags_str.append(features.int2str(tag))\n",
    "print(\"Текстовые NER метки токенов\")\n",
    "print(tags_str)\n",
    "print(\"Токены после работы токенайзера BERT\")\n",
    "print(bert_tokenizer(example[\"tokens\"], is_split_into_words=True).tokens())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48468ae1-48d3-4641-ada4-0a8cf25e50ad",
   "metadata": {},
   "source": [
    "Вспомним немного, как работают метки в задаче мер в кодировке IOB. В данной задаче у нас есть 4 типа именованных сущностей:\n",
    "* PER - персона\n",
    "* ORG - организация\n",
    "* LOC - локация\n",
    "* MISC - другое\n",
    "* O - отсутствие именованной сущности\n",
    "\n",
    "У каждого типа именованных 2 префикса:\n",
    "* `B-` - beginning, т.е. начало именованной сущности.\n",
    "* `I-` - inside, т.е. продолжение ранее начатой именованной сущностью.\n",
    "\n",
    "В исходной токенизации\n",
    "\n",
    "`['Rabinovich', 'is', 'winding', 'up', 'his', 'term', 'as', 'ambassador', '.']`\n",
    "метки выглядят как \n",
    "\n",
    "`['B-PER', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']`\n",
    "т.е. `Rabinovich` является персоной. На следующем токене именованная сущность заканчивается, т.к. у него метка `O`.\n",
    "\n",
    "После токенизации BERT наш сэмпл превращается в следующие токены:\n",
    "\n",
    "`['[CLS]', 'Ra', '##bino', '##vich', 'is', 'winding', 'up', 'his', 'term', 'as', 'ambassador', '.', '[SEP]']`\n",
    "Обратим внимание, что один токен `Rabinovich` с меткой `B-PER` был разбит токенизатором берта на 3 токена: `'Ra', '##bino', '##vich'`. Им нужно поставить в соответствие 3 метки: `B-PER, I-PER, I-PER`, т.е. мы разбиваем метку исходного токена на новые токены.\n",
    "\n",
    "Также обратим внимание на первый и последний токен - это спецстокены BERT означающие начало и конец текста. Им можно дать метки `O`, т.к. они не являются частью исходного текста, но мы будем давать им особое векторизированное значение -100. В [документации pytroch](https://pytorch.org/docs/stable/generated/torch.nn.CrossEntropyLoss.html) у кроссэнтропийной функции потерь это дефолтное значение `ignore_index`, т.е. метки, которую мы будем игнорировать. Библиотека transformers также использует это значение. Таким образом на токенах, у которых стоит -100 в качестве векторизированного NER-тэга, не будет происходить обучение, они будут проигнорированы.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c6ac7b9-d65f-4e09-8165-de5442a6ab6e",
   "metadata": {},
   "source": [
    "Напишите функцию `preprocess_ner_dataset`, которая разворачивает `ner_tags` для слов в тэги для BERT-токенов и готовит остальные данные для обучения (можно разделить на две функции или написать всё в одной). В резултате применения `conll2003.map(preprocess_ner_dataset)`, в каждом примере:\n",
    "1. Добавляется токенизированный вход (`input_ids`, `token_type_ids` и `attention_mask`). При конструировании этих векторов вручную нужно проставить `attention_mask` полностью единицами, т.к. в паддинги в сэмплах появляются только в рамках батчей, а `token_type_ids` полностью нулями.\n",
    "2. `ner_tags` разворачивается в `labels` для входных токенов\n",
    "\n",
    "Что можно использовать:\n",
    "* у объекта `conll2003[\"train\"].features[\"ner_tags\"].feature` есть методы `int2str` и `str2int` для превращение векторизованного NER-тэга в строковый вид и обратно\n",
    "* Спецтокенам BERT нужно поставить значение -100\n",
    "* вызов `bert_tokenizer(bert_tokenizer(example[\"tokens\"], is_split_into_words=True)` возвращает вам input_ids, attention_mask, token_type_ids\n",
    "* Вызов `bert_tokenizer(example[\"tokens\"], is_split_into_words=True, return_offsets_mapping=True))` возвращает дополнительно offset_mapping, позиции новых токенов в оригинальном тексте\n",
    "* `bert_tokenizer.vocab` - для превращения токенов в их индексы в словаре\n",
    "* `bert_tokenizer.tokenize` - разбитие текста (в том числе и исходных токенов) на токены BERT\n",
    "\n",
    "Ваша задача:\n",
    "1. Создать новый dict, в котором будут input_ids, attention_mask, token_type_ids\n",
    "2. Добавить в него labels - векторизированные NER-тэги, которые будут разбиты в соответствии с токенизацией BERT. Для этого можно можно разбить каждый токен отдельно и размножить его метки. Альтернативно можно использовать информацию об оффсетах токенов BERT, чтобы понять, частью какого исходного токена и какой исходной метки является данный BERT-токен."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "75dd55d2-61f8-4591-8b53-999cca29ee8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import groupby\n",
    "\n",
    "def preprocess_ner_dataset(example):\n",
    "    tokens = example[\"tokens\"]\n",
    "    ner_tags = example[\"ner_tags\"]\n",
    "    \n",
    "    tokenized = bert_tokenizer(tokens, is_split_into_words=True, return_offsets_mapping=True)\n",
    "    \n",
    "    input_ids = tokenized[\"input_ids\"]\n",
    "    attention_mask = tokenized[\"attention_mask\"]\n",
    "    token_type_ids = tokenized[\"token_type_ids\"]\n",
    "    \n",
    "    labels = []\n",
    "    word_ids = tokenized.word_ids()\n",
    "    \n",
    "    previous_word_idx = None\n",
    "    for word_idx in word_ids:\n",
    "        if word_idx is None:\n",
    "            labels.append(-100)  # спецтокены\n",
    "        else:\n",
    "            if word_idx != previous_word_idx:\n",
    "                labels.append(ner_tags[word_idx])  # оригинальный тег слова\n",
    "            else:\n",
    "                # если первый токен был 'B-*', то делаем 'I-*'\n",
    "                prev_tag = ner_tags[word_idx]\n",
    "                if features.int2str(prev_tag).startswith(\"B-\"):\n",
    "                    labels.append(features.str2int(\"I-\" + features.int2str(prev_tag)[2:]))\n",
    "                else:\n",
    "                    labels.append(prev_tag)  # иначе просто повторяем тег\n",
    "        previous_word_idx = word_idx\n",
    "\n",
    "    # Проверяем размерности\n",
    "    assert len(labels) == len(input_ids), f\"Mismatch: {len(labels)} labels and {len(input_ids)} tokens\"\n",
    "\n",
    "    return {\n",
    "        \"input_ids\": input_ids,\n",
    "        \"token_type_ids\": token_type_ids,\n",
    "        \"attention_mask\": attention_mask,\n",
    "        \"labels\": labels\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4c9ed654-c4dc-4757-a000-b44bcb2f5393",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert preprocess_ner_dataset(conll2003[\"train\"][0]) == {\n",
    "    'input_ids': [101, 7270, 22961, 1528, 1840, 1106, 21423, 1418, 2495, 12913, 119, 102], \n",
    "    'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], \n",
    "    'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], \n",
    "    'labels': [-100, 3, 0, 7, 0, 0, 0, 7, 0, 0, 0, -100]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeb77fcb-4d0a-4e7d-bae8-4b1d25549e38",
   "metadata": {},
   "source": [
    "### Тесты"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5a8af22c-9da2-4bf0-a2f2-5808c72703d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_example = preprocess_ner_dataset(example)\n",
    "required_keys = [\"input_ids\", \"labels\", \"attention_mask\", \"token_type_ids\"]\n",
    "for k in required_keys:\n",
    "    assert k in processed_example, f\"Отсутствует поле {k}\"\n",
    "\n",
    "required_keys_set = set(required_keys)\n",
    "for k in processed_example.keys():\n",
    "    assert k in required_keys_set, f\"В примере лишнее поле {k}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9a334417-49d8-4b02-8599-0914e1474671",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10it [00:00, 1432.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Токенизация верна!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "for idx, example in tqdm(enumerate(conll2003[\"train\"])):\n",
    "    input_ids_real = bert_tokenizer(example[\"tokens\"], is_split_into_words=True)[\"input_ids\"]\n",
    "    input_ids_ours = preprocess_ner_dataset(example)[\"input_ids\"]\n",
    "    assert input_ids_real == input_ids_ours, f\"Ошибка токенизации на примере {idx}\"\n",
    "    if idx >= 10:\n",
    "        break\n",
    "print(\"Токенизация верна!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7bb5b4f4-3958-4421-8136-17facfd19cd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "example = conll2003[\"train\"][100]\n",
    "processed_example = preprocess_ner_dataset(example)\n",
    "\n",
    "assert processed_example[\"labels\"][0] == -100\n",
    "assert processed_example[\"labels\"][-1] == -100\n",
    "ner_tags = [features.int2str(i) for i in processed_example[\"labels\"][1:-1]]\n",
    "assert ner_tags == ['B-PER', 'I-PER', 'I-PER', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c04cc2a3-7d89-4b8b-a943-7c9fe10ca561",
   "metadata": {},
   "outputs": [],
   "source": [
    "example = conll2003[\"train\"][200]\n",
    "processed_example = preprocess_ner_dataset(example)\n",
    "\n",
    "assert processed_example[\"labels\"][0] == -100\n",
    "assert processed_example[\"labels\"][-1] == -100\n",
    "ner_tags = [features.int2str(i) for i in processed_example[\"labels\"][1:-1]]\n",
    "assert ner_tags == ['B-ORG', 'I-ORG', 'I-ORG', 'I-ORG']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea8177dc-ab7b-4b67-8676-73c57e5b01f6",
   "metadata": {},
   "source": [
    "Применим нашу функцию к всему датасету"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "106c8045-8883-46b1-ab95-0904f838a2de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['id', 'tokens', 'pos_tags', 'chunk_tags', 'ner_tags', 'input_ids', 'token_type_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 14041\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['id', 'tokens', 'pos_tags', 'chunk_tags', 'ner_tags', 'input_ids', 'token_type_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 3250\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['id', 'tokens', 'pos_tags', 'chunk_tags', 'ner_tags', 'input_ids', 'token_type_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 3453\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessed_ner_dataset = conll2003.map(preprocess_ner_dataset, num_proc=1)\n",
    "preprocessed_ner_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98eb4ddd-3487-4785-80a6-0f821a7e4b9a",
   "metadata": {},
   "source": [
    "Подготовим `data_collator`. Это особый класс, который будет заниматься батчеванием сэмплов для обучения. Он добавит паддинги во все необходимые поля."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a20511a1-d222-4034-b099-9dfdd02ed81b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "transformers.data.data_collator.DataCollatorForTokenClassification"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import DataCollatorForTokenClassification\n",
    "\n",
    "\n",
    "data_collator = DataCollatorForTokenClassification(tokenizer=bert_tokenizer)\n",
    "type(data_collator)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0c7c640-ac2b-4388-81b6-9f21c8c2ec2d",
   "metadata": {},
   "source": [
    "### Подготовка модели (5 баллов)\n",
    "\n",
    "Два возможных пути на этой стадии:\n",
    "1. Взять [готовый класс](https://huggingface.co/docs/transformers/model_doc/auto#transformers.AutoModelForTokenClassification) модели для классификации токенов. (Этот вариант настоятельно рекомендуется). Ему нужно подать num_labels - число классов (число возможных меток для токенов), id2label - словарь индекс метки -> текст метки , label2id - словарь текст метки -> индекс метки. Из-за непростого наследования эти аргументы тяжело найти, прочитать про них можно [тут](https://huggingface.co/docs/transformers/en/main_classes/configuration#transformers.PretrainedConfig)\n",
    "2. Взять модель как фича экстрактор ([AutoModel](https://huggingface.co/transformers/v3.0.2/model_doc/auto.html#automodel)) и самостоятельно добавить классификационную голову. Вдохновиться можно по [ссылке](https://github.com/huggingface/transformers/blob/main/src/transformers/models/bert/modeling_bert.py#L1847-L1860).\n",
    "\n",
    "Результатом должна быть модель, которая для каждого токена возвращает логиты/вероятности для `conll2003[\"train\"].features[\"ner_tags\"].feature.num_classes` классов.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "331cd38a-3501-4f41-9193-8cf6579ad80e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForTokenClassification, AutoModel\n",
    "\n",
    "label_names = conll2003[\"train\"].features[\"ner_tags\"].feature.names\n",
    "id2label = {i: label for i, label in enumerate(label_names)}\n",
    "label2id = {label: i for i, label in enumerate(label_names)}\n",
    "\n",
    "bert_ner = AutoModelForTokenClassification.from_pretrained(\n",
    "    BASE_NER_MODEL, \n",
    "    num_labels=conll2003[\"train\"].features[\"ner_tags\"].feature.num_classes,\n",
    "    id2label=id2label, \n",
    "    label2id=label2id,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73eaa2ce-0f56-4b8f-8829-ff9edffa0d34",
   "metadata": {},
   "source": [
    "### Подготовим Метрику (5 баллов)\n",
    "\n",
    "Дополните функцию, используя `metrics_calculator`, чтобы она возвращала `accuracy`, `precision`, `recall` и `f-меру`. `eval_predictions` - это кортеж из логитов токен классификатора и `labels`, которые мы подготовили с помощью `preprocess_ner_dataset`. Нужно\n",
    "1. Преобразовать логиты в предсказанные лейблы. Учтите, что для специальных токенов лейблов нет. В этом нам поможет argmax.\n",
    "2. Убрать паддинги - это те позиции, где метки (labels) равняются -100\n",
    "3. Перевести labels из чисел в текстовые метки с помощью `label_list`\n",
    "4. Посчитать метрики с помощью `metrics_calculator`\n",
    "5. Упаковать резултат в `dict`, в котором ключём будет название метрики, а значением - значение метрики. Брать можно только `overall_*` метрики для удобства\n",
    "\n",
    "В logits будет лежать тензор размерности \\[размер eval датасета, максимальная длина последовательности, число меток\\], содержащий предсказания модели\n",
    "\n",
    "В target_labels будет лежать тензор размерности \\[размер eval датасета, максимальная длина последовательности\\], содержащий метки из валидационной выборки.\n",
    "\n",
    "Примеры функции calculate_metrics можно посмотреть в [документации](https://huggingface.co/docs/evaluate/en/transformers_integrations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b736c422",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['O', 'B-PER', 'I-PER', 'B-ORG', 'I-ORG', 'B-LOC', 'I-LOC', 'B-MISC', 'I-MISC']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_list = conll2003[\"train\"].features[\"ner_tags\"].feature.names\n",
    "label_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c096f958",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'MISC': {'precision': np.float64(0.0), 'recall': np.float64(0.0), 'f1': np.float64(0.0), 'number': np.int64(1)}, 'PER': {'precision': np.float64(1.0), 'recall': np.float64(1.0), 'f1': np.float64(1.0), 'number': np.int64(1)}, 'overall_precision': np.float64(0.5), 'overall_recall': np.float64(0.5), 'overall_f1': np.float64(0.5), 'overall_accuracy': 0.8}\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import evaluate\n",
    "\n",
    "\n",
    "metrics_calculator = evaluate.load(\"seqeval\")\n",
    "label_list = conll2003[\"train\"].features[\"ner_tags\"].feature.names\n",
    "\n",
    "y_true = [['O', 'O', 'O', 'B-MISC', 'I-MISC', 'I-MISC', 'O'], ['B-PER', 'I-PER', 'O']]\n",
    "y_pred = [['O', 'O', 'B-MISC', 'I-MISC', 'I-MISC', 'I-MISC', 'O'], ['B-PER', 'I-PER', 'O']]\n",
    "\n",
    "print(metrics_calculator.compute(references=y_true, predictions=y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "55ad18b4-5176-4bf1-ab9a-517466e79f70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'overall_precision': np.float64(0.5), 'overall_recall': np.float64(0.5), 'overall_f1': np.float64(0.5), 'overall_accuracy': 0.8}\n"
     ]
    }
   ],
   "source": [
    "def calculate_metrics(eval_predictions):\n",
    "    logits, labels = eval_predictions\n",
    "\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "\n",
    "    true_labels = []\n",
    "    pred_labels = []\n",
    "    \n",
    "    for label_seq, pred_seq in zip(labels, predictions):\n",
    "        true_seq = []\n",
    "        pred_seq_filtered = []\n",
    "        for label, pred in zip(label_seq, pred_seq):\n",
    "            if label != -100:\n",
    "                true_seq.append(label_list[label])\n",
    "                pred_seq_filtered.append(label_list[pred])\n",
    "        true_labels.append(true_seq)\n",
    "        pred_labels.append(pred_seq_filtered)\n",
    "\n",
    "    results = metrics_calculator.compute(references=true_labels, predictions=pred_labels)\n",
    "\n",
    "    return {key: value for key, value in results.items() if key.startswith(\"overall\")}\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "logits = np.array([\n",
    "    [  # Batch 1\n",
    "        [7, 0, 0, 0, 0, 0, 0, 0, 0],  # 'O'\n",
    "        [7, 0, 0, 0, 0, 0, 0, 0, 0],  # 'O'\n",
    "        [0, 0, 0, 0, 0, 0, 0, 7, 0],  # 'B-MISC'\n",
    "        [0, 0, 0, 0, 0, 0, 0, 0, 7],  # 'I-MISC'\n",
    "        [0, 0, 0, 0, 0, 0, 0, 0, 7],  # 'I-MISC'\n",
    "        [0, 0, 0, 0, 0, 0, 0, 0, 7],  # 'I-MISC'\n",
    "        [7, 0, 0, 0, 0, 0, 0, 0, 0],  # 'O'\n",
    "    ],\n",
    "    [  # Batch 2\n",
    "        [0, 12, 0, 0, 0, 0, 0, 0, 0],  # 'B-PER'\n",
    "        [0, 0, 10, 0, 0, 0, 0, 0, 0],  # 'I-PER'\n",
    "        [12, 0, 0, 0, 0, 0, 0, 0, 0],  # 'O'\n",
    "        [0, 12, 0, 0, 0, 0, 0, 0, 0],  # 'B-PER' - но не оно по паддингам, поэтому не должно считаться в метрике!\n",
    "        [0, 0, 12, 0, 0, 0, 0, 0, 0],  # 'I-PER'\n",
    "        [0, 0, 12, 0, 0, 0, 0, 0, 0],  # 'I-PER'\n",
    "        [0, 0, 12, 0, 0, 0, 0, 0, 0],  # 'I-PER'\n",
    "    ]\n",
    "])\n",
    "\n",
    "labels = np.array([\n",
    "    [0, 0, 0, 7, 8, 8, 0],  # 'O', 'O', 'O', 'B-MISC', 'I-MISC', 'I-MISC', 'O'\n",
    "    [1, 2, 0, -100, -100, -100, -100]  # 'B-PER', 'I-PER', 'O' (with padding -100s)\n",
    "])\n",
    "\n",
    "logits_res = [[\"O\", \"O\", \"B-MISC\", \"I-MISC\", \"I-MISC\", \"I-MISC\", \"O\"], [\"B-PER\", \"I-PER\", \"O\"]]\n",
    "labels_res = [[\"O\", \"O\", \"O\", \"B-MISC\", \"I-MISC\", \"I-MISC\", \"O\"], [\"B-PER\", \"I-PER\", \"O\"]]\n",
    "\n",
    "metrics_on_tensors = calculate_metrics((logits, labels))\n",
    "print(metrics_on_tensors)\n",
    "metrics_on_strs = metrics_calculator.compute(references=logits_res, predictions=labels_res)\n",
    "\n",
    "for k in metrics_on_tensors:\n",
    "    if \"overall\" in k:\n",
    "        assert metrics_on_tensors[k] == metrics_on_strs[k], k\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c44528ae-e63a-4561-b707-a891f8dcf75f",
   "metadata": {},
   "source": [
    "### Обучение (5 баллов)\n",
    "\n",
    "Два возможных пути на этой стадии:\n",
    "\n",
    "1. Использовать [Trainer](https://huggingface.co/transformers/v3.0.2/main_classes/trainer.html) класс из `transformers`\n",
    "2. Написать свой training loop\n",
    "\n",
    "Опишем подробнее первый путь, т.к. он настоятельно рекомендуется.\n",
    "\n",
    "Нужно создать класс Trainer и TrainingArguments.\n",
    "В [TrainingArguments](https://huggingface.co/docs/transformers/en/main_classes/trainer#transformers.TrainingArguments) нужно как минимум следующие поля:\n",
    "* save_strategy, eval_strategy\n",
    "* metric_for_best_model (исходя из calculate_metrics), greater_is_better\n",
    "* learning_rate (возьмите 2e-5)\n",
    "* num_train_epochs\n",
    "* per_device_train_batch_size, per_device_eval_batch_size\n",
    "\n",
    "В класс Trainer нужно передать:\n",
    "* model\n",
    "* в args нужно передать заполненные TrainingArguments\n",
    "* train_dataset, eval_dataset\n",
    "* tokenizer\n",
    "* compute_metrics\n",
    "\n",
    "После чего запустить `trainer.train()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8eaa5d5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a3593874-6c27-464d-a424-603f7c4ab4a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='5268' max='5268' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [5268/5268 1:48:57, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Overall Precision</th>\n",
       "      <th>Overall Recall</th>\n",
       "      <th>Overall F1</th>\n",
       "      <th>Overall Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.073700</td>\n",
       "      <td>0.074339</td>\n",
       "      <td>0.896260</td>\n",
       "      <td>0.927634</td>\n",
       "      <td>0.911677</td>\n",
       "      <td>0.980441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.033100</td>\n",
       "      <td>0.071227</td>\n",
       "      <td>0.934377</td>\n",
       "      <td>0.944127</td>\n",
       "      <td>0.939227</td>\n",
       "      <td>0.984738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.019900</td>\n",
       "      <td>0.063235</td>\n",
       "      <td>0.931120</td>\n",
       "      <td>0.948670</td>\n",
       "      <td>0.939813</td>\n",
       "      <td>0.986078</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=5268, training_loss=0.05200552922265495, metrics={'train_runtime': 6539.6404, 'train_samples_per_second': 6.441, 'train_steps_per_second': 0.806, 'total_flos': 920771584279074.0, 'train_loss': 0.05200552922265495, 'epoch': 3.0})"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import Trainer, TrainingArguments\n",
    "\n",
    "# Определяем параметры обучения\n",
    "args = TrainingArguments(\n",
    "    output_dir = \"./results\",\n",
    "    eval_strategy = \"epoch\",\n",
    "    save_strategy = \"epoch\",\n",
    "    metric_for_best_model = \"overall_f1\",\n",
    "    greater_is_better = True,\n",
    "    learning_rate = 2e-5,\n",
    "    num_train_epochs = 3,\n",
    "    per_device_train_batch_size = 8,\n",
    "    per_device_eval_batch_size = 8,\n",
    "    save_total_limit = 2,\n",
    "    load_best_model_at_end = True,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model = bert_ner,\n",
    "    args = args,\n",
    "    train_dataset = preprocessed_ner_dataset[\"train\"],\n",
    "    eval_dataset = preprocessed_ner_dataset[\"validation\"],\n",
    "    compute_metrics = calculate_metrics,\n",
    "    data_collator = data_collator,\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6816c756",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'test_loss': 0.19507157802581787,\n",
       " 'test_overall_precision': 0.8865820178448868,\n",
       " 'test_overall_recall': 0.9148371104815864,\n",
       " 'test_overall_f1': 0.9004879749041479,\n",
       " 'test_overall_accuracy': 0.9715730921353272,\n",
       " 'test_runtime': 94.5455,\n",
       " 'test_samples_per_second': 36.522,\n",
       " 'test_steps_per_second': 4.569}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "*_, metrics = trainer.predict(preprocessed_ner_dataset['test'])\n",
    "metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbe8a152-f724-4c8d-9949-74e346b6a842",
   "metadata": {},
   "source": [
    "### Обработка результатов Результатов (5 баллов)\n",
    "\n",
    "Подумать о:\n",
    "1. Во время подготовки данных мы приобразовали BIO разметку. Как обратить это преобразование с помощью токенайзера?\n",
    "\n",
    "Провалидируйте результаты на тестовом датасете."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fda7c62-f8eb-4a83-9659-71ef3a8610fb",
   "metadata": {},
   "source": [
    "Можете сравнить результат с [лидербордом](https://paperswithcode.com/sota/token-classification-on-conll2003).\n",
    "\n",
    "\n",
    "Напишите функцию, которая принимает на вход текст и отдаёт такой словарь:\n",
    "\n",
    "```json\n",
    "{\n",
    "    \"text\": \"входной текст\",\n",
    "    \"entities\": [\n",
    "        {\n",
    "            \"class\": \"лейбл класса\",\n",
    "            \"text\": \"текстовое представление\",\n",
    "            \"start\": \"оффсет от начала строки до начала entity\",\n",
    "            \"end\": \"оффсет от начала строки до конца entity\"\n",
    "        },\n",
    "        ...\n",
    "    ]\n",
    "}\n",
    "```\n",
    "\n",
    "Должно выполняться такое условие:\n",
    "\n",
    "```python\n",
    "text[entity[\"start\"]:entity[\"stop\"]] == entity[\"text\"]\n",
    "```\n",
    "\n",
    "1. Вначале нужно токенизировать текст. На вход принимается любой текст без **предварительной токенизации**!\n",
    "2. Текст нужно прогнать через модель, после чего получатся логиты классов, с помощью которых можно получить индексы меток\n",
    "3. После этого стоит декодировать сущность и записать ее координаты. Сущность начинается или с B-метки или с метки I- при условии, что сменился класс. Т.е. метки B-PER, I-PER, I-MISC должны декодироваться 2 сущности PER и MISC!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "be10dcb5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[ 101, 8667, 1362,  102]]), 'token_type_ids': tensor([[0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1]]), 'offset_mapping': tensor([[[ 0,  0],\n",
       "         [ 0,  5],\n",
       "         [ 6, 11],\n",
       "         [ 0,  0]]])}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bert_tokenizer(\"Hello world\", return_offsets_mapping=True, return_tensors=\"pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "1c24199c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Tuple\n",
    "text = \"Иван Иванов caterpillar Apple Стив Джобс\"\n",
    "labels = [\"I-PER\", \"I-PER\", \"I-MISC\", \"B-MISC\", \"B-PER\", \"B-PER\"]\n",
    "offsets = [(0, 4), (5, 11), (12, 23), (24, 29), (30, 34), (35, 40)]\n",
    "\n",
    "def decode_entities(text: str, labels: List[str], offsets: List[Tuple[int, int]]):\n",
    "    entities = []\n",
    "    current_entity = None\n",
    "    current_class = None\n",
    "    \n",
    "    for i, (label, (start, end)) in enumerate(zip(labels, offsets)):\n",
    "        if label.startswith(\"B-\"):\n",
    "            if current_entity:\n",
    "                entities.append(current_entity)\n",
    "            current_class = label[2:]\n",
    "            current_entity = {\"class\": current_class, \"text\": text[start:end], \"start\": start, \"end\": end}\n",
    "        elif label.startswith(\"I-\"):\n",
    "            entity_class = label[2:]\n",
    "            if current_entity and current_class == entity_class:\n",
    "                current_entity[\"text\"] += \" \" + text[start:end]\n",
    "                current_entity[\"end\"] = end\n",
    "            else:\n",
    "                if current_entity:\n",
    "                    entities.append(current_entity)\n",
    "                current_class = entity_class\n",
    "                current_entity = {\"class\": current_class, \"text\": text[start:end], \"start\": start, \"end\": end}\n",
    "    \n",
    "    if current_entity:\n",
    "        entities.append(current_entity)\n",
    "    \n",
    "    return {\"text\": text, \"entities\": entities}\n",
    "\n",
    "assert decode_entities(text, labels, offsets) == {\n",
    "    'text': 'Иван Иванов caterpillar Apple Стив Джобс',\n",
    "    'entities': [\n",
    "        {'class': 'PER', 'text': 'Иван Иванов', 'start': 0, 'end': 11},\n",
    "        {'class': 'MISC', 'text': 'caterpillar', 'start': 12, 'end': 23},\n",
    "        {'class': 'MISC', 'text': 'Apple', 'start': 24, 'end': 29},\n",
    "        {'class': 'PER', 'text': 'Стив', 'start': 30, 'end': 34},\n",
    "        {'class': 'PER', 'text': 'Джобс', 'start': 35, 'end': 40}\n",
    "    ]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67894d03",
   "metadata": {},
   "source": [
    "В функции do_ner нужно токенизировать текст, получить выходы модели на тексте и подать все в decode_entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "1c8f48b4-932d-4525-b8d7-8b57f324520d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'text': 'Ivan Petrov is going to start working tomorrow', 'entities': [{'class': 'PER', 'text': 'Ivan Pet rov', 'start': 0, 'end': 11}]}\n"
     ]
    }
   ],
   "source": [
    "@torch.no_grad()\n",
    "def do_ner(text: str):\n",
    "    bert_ner.eval()\n",
    "    \n",
    "    tokens = bert_tokenizer(text, return_offsets_mapping=True, return_tensors=\"pt\", is_split_into_words=False)\n",
    "    input_ids = tokens[\"input_ids\"]\n",
    "    offsets = tokens[\"offset_mapping\"].tolist()[0]\n",
    "    \n",
    "    outputs = bert_ner(input_ids).logits\n",
    "    predicted_labels = torch.argmax(outputs, dim=-1)[0].tolist()\n",
    "    \n",
    "    label_names = [bert_ner.config.id2label[idx] for idx in predicted_labels]\n",
    "    \n",
    "    valid_offsets = [(start, end) for (start, end) in offsets if start != end]\n",
    "    \n",
    "    return decode_entities(text, label_names, valid_offsets)\n",
    "\n",
    "# Тестовый пример\n",
    "print(do_ner(\"Ivan Petrov is going to start working tomorrow\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a22542f-17e7-4a33-8dc4-f5b94611fa1f",
   "metadata": {},
   "source": [
    "Почистим память перед второй частью."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "7516c7bb-88ac-4d60-a6a0-4cfebd6fa0ad",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'bert_ner' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Professional\\Desktop\\LLM\\nlp\\task2\\hw2_practice.ipynb Ячейка 43\u001b[0m line \u001b[0;36m3\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Professional/Desktop/LLM/nlp/task2/hw2_practice.ipynb#X56sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtorch\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Professional/Desktop/LLM/nlp/task2/hw2_practice.ipynb#X56sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mdel\u001b[39;00m bert_ner\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Professional/Desktop/LLM/nlp/task2/hw2_practice.ipynb#X56sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39mdel\u001b[39;00m trainer\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Professional/Desktop/LLM/nlp/task2/hw2_practice.ipynb#X56sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m torch\u001b[39m.\u001b[39mcpu\u001b[39m.\u001b[39mcurrent_device()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'bert_ner' is not defined"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "del bert_ner\n",
    "del trainer\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8eb83f8",
   "metadata": {},
   "source": [
    "## Классификация с T5 (25 баллов)\n",
    "\n",
    "Требуется дообучить [t5-small](https://huggingface.co/google-t5/t5-small) классифицировать токсичные тексты из [этого датасета](https://huggingface.co/datasets/lmsys/toxic-chat). Классификатор должен работать в стиле t5 - генерировать ответ текстом.\n",
    "\n",
    "1. Подготовить данные для бинарной классификации\n",
    "\t1. Придумать префикс для задачи или взять из похожей модели\n",
    "\t2. Выбрать тексты для обозначения классов\n",
    "2. Обучить t5-small на генерацию выбранных названия классов\n",
    "3. Сравнить с модель с аналогичной предобученной моделью\n",
    "\n",
    "### Подготовка Данных (6 баллов)\n",
    "\n",
    "Подумать о:\n",
    "1) Какой префикс выбрать для новой задачи?\n",
    "2) Должен ли префикс быть понятным?\n",
    "3) Как выбрать метку для класса? \n",
    "4) Что будет, если метки класса целиком нет в словаре?\n",
    "5) Что делать с длинными текстами?\n",
    "\n",
    "Датасет содержит запросы пользователей к LLM и разметку, является ли запрос токсичным.}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "aa9e5469",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b861ceda15a043348175edcafefe2a4d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/2.32k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f06366239b2f4a008cd870cb9fc16530",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b12b482919b94ea2a82fcb71dffb8848",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.39M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c6181966297e425db13be818e315741b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/5.46k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a323870063141bc871b5a024ca98ec3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "toxic-chat_annotation_train.csv:   0%|          | 0.00/8.20M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "791d3c7ba63c45ee86952459b635dd8e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "toxic-chat_annotation_test.csv:   0%|          | 0.00/8.09M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9434c5b1f84c4d0985e95d57f890270f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f635252b54e6478b97f4cc75c7a1e245",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "\n",
    "BASE_T5_MODEL= \"t5-small\"\n",
    "t5_tokenizer = AutoTokenizer.from_pretrained(BASE_T5_MODEL)\n",
    "\n",
    "\n",
    "toxic_chat_dataset = load_dataset(\"lmsys/toxic-chat\", \"toxicchat0124\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73b8ddc6",
   "metadata": {},
   "source": [
    "Место для изучения датасета:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "4c04b2cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'conv_id': 'e0c9b3e05414814485dbdcb9a29334d502e59803af9c26df03e9d1de5e7afe67',\n",
       " 'user_input': 'Masturbacja jest proces co oitrzebuje',\n",
       " 'model_output': 'Masturbacja to proces, który może pozytywnie wpłynąć na zdrowie psychiczne i fizyczne człowieka, ponieważ pomaga w relaksie, redukuje stres i pomaga w uśpieniu. Może też być używana jako dodatkowa form',\n",
       " 'human_annotation': True,\n",
       " 'toxicity': 0,\n",
       " 'jailbreaking': 0,\n",
       " 'openai_moderation': '[[\"sexual\", 0.4609803557395935], [\"sexual/minors\", 0.0012527990620583296], [\"harassment\", 0.0001862536446424201], [\"hate\", 0.00015521160094067454], [\"violence\", 6.580814078915864e-05], [\"self-harm\", 3.212967567378655e-05], [\"violence/graphic\", 1.5190824342425913e-05], [\"self-harm/instructions\", 1.0009921425080393e-05], [\"hate/threatening\", 4.4459093260229565e-06], [\"self-harm/intent\", 3.378846486157272e-06], [\"harassment/threatening\", 1.7095695739044459e-06]]'}"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "toxic_chat_dataset[\"train\"][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "488f6572",
   "metadata": {},
   "source": [
    "Нас будут интересовать колонки `\"user_input\"` и `\"toxicity\"`. Убираем ненужные колонки из датасета:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "1a0b9651",
   "metadata": {},
   "outputs": [],
   "source": [
    "toxic_chat_dataset = toxic_chat_dataset.remove_columns(\n",
    "    [\"conv_id\", \"model_output\", \"human_annotation\", \"jailbreaking\", \"openai_moderation\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21f0f249",
   "metadata": {},
   "source": [
    "![](https://production-media.paperswithcode.com/methods/new_text_to_text.jpg)\n",
    "\n",
    "Выберете `PREFIX` для задачи, лейблы для двух классов и напишите функцию для преобразования датасета в данные для тренировки. Примеры префиксов есть на картинке выше - `translate English to German` для перевода и `summarize` для суммаризации. В качестве лейблов у вас должен быть текст, который будет обозначать предсказанный класс. Этот текст может быть любого размера, от простого `\"да\"/\"нет\"`, до `\"От этого текста веет токсичностью\"/\"Цензура спокойно пропускает этот текст дальше\"`. Подумайте в чём преимущество первого подхода перед вторым.\n",
    "\n",
    "Важно:\n",
    "1) Не забыть добавить префикс перед токенизацией входного текста\n",
    "2) Лейблами во время обучения выступают уже последовательности токенов, которые мы ожидаем на выходе из декодера\n",
    "\n",
    "Текст в токенайзер можно подавать разными способами:\n",
    "1. `tokenizer(text=\"text\")` - токенизируй текст как обычно\n",
    "1. `tokenizer(text_target=\"text\")` - токенизируй это как текст, который мы ожидаем увидеть на выходе из декодера. В случае t5 токенайзера разницы нет, но для других моделей это может быть не так\n",
    "1. Другие методы можно узнать посмотрев сигнатуру метода `tokenizer.__call__`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "2ce39484",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a771387c5a03464a95f0b878aa703e4a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/5082 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ecd7cff8fbc74ef2a32d4800a82364ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/5083 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['user_input', 'toxicity', 'input_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 5082\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['user_input', 'toxicity', 'input_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 5083\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PREFIX = \"Classify toxicity: \"\n",
    "MAX_LENGTH = 512\n",
    "\n",
    "id2label = {\n",
    "    0: \"Этот текст безопасен\",\n",
    "    1: \"Этот текст токсичен\"\n",
    "}\n",
    "\n",
    "def preprocess_dataset(example):\n",
    "    input_texts = PREFIX + example[\"user_input\"]\n",
    "    model_inputs = t5_tokenizer(input_texts, truncation=True, max_length=MAX_LENGTH)\n",
    "    model_inputs[\"labels\"] = t5_tokenizer(id2label[example[\"toxicity\"]]).input_ids\n",
    "    return model_inputs\n",
    "\n",
    "toxic_chat_dataset = toxic_chat_dataset.map(preprocess_dataset)\n",
    "\n",
    "toxic_chat_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "549a1f82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'user_input': 'Masturbacja jest proces co oitrzebuje',\n",
       " 'toxicity': 0,\n",
       " 'input_ids': [4501,\n",
       "  4921,\n",
       "  3,\n",
       "  27147,\n",
       "  10,\n",
       "  6664,\n",
       "  2905,\n",
       "  9305,\n",
       "  1191,\n",
       "  528,\n",
       "  7,\n",
       "  17,\n",
       "  6345,\n",
       "  576,\n",
       "  3,\n",
       "  32,\n",
       "  155,\n",
       "  52,\n",
       "  776,\n",
       "  3007,\n",
       "  1924,\n",
       "  1],\n",
       " 'attention_mask': [1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1],\n",
       " 'labels': [3,\n",
       "  2,\n",
       "  9592,\n",
       "  6725,\n",
       "  3,\n",
       "  14982,\n",
       "  6652,\n",
       "  10458,\n",
       "  3,\n",
       "  2,\n",
       "  1757,\n",
       "  2,\n",
       "  2044,\n",
       "  2,\n",
       "  2533,\n",
       "  5345,\n",
       "  22123,\n",
       "  1]}"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "toxic_chat_dataset['train'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "666efd29",
   "metadata": {},
   "source": [
    "Пример результата:\n",
    "```json\n",
    "{'user_input': 'Do you know drug which name is abexol ?',\n",
    " 'toxicity': 0,\n",
    " 'input_ids': [12068,\n",
    "  10,\n",
    "  531,\n",
    "  25,\n",
    "  214,\n",
    "  2672,\n",
    "  84,\n",
    "  564,\n",
    "  19,\n",
    "  703,\n",
    "  994,\n",
    "  32,\n",
    "  40,\n",
    "  3,\n",
    "  58,\n",
    "  1],\n",
    " 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
    " 'labels': [150, 1]}\n",
    "```\n",
    "Значения в `'labels'` в вашем случае могут отличаться, это зависит от выбранного вами текстового представления в `id2label` словаре.\n",
    "\n",
    "\n",
    "Инициализируем соответствующий задаче `DataCollator`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "0c17549d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DataCollatorForSeq2Seq\n",
    "\n",
    "\n",
    "data_collator = DataCollatorForSeq2Seq(tokenizer=t5_tokenizer, model=seq2seq_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "711d6dfd",
   "metadata": {},
   "source": [
    "### Определим метрику (2 балла)\n",
    "\n",
    "В этой задаче метрика простая - `accuracy`. Можно добавить другие метрики по желанию. Функция `compute_metric` должна возвращать словарь, аналогично функции `calculate_metrics` ранее:\n",
    "\n",
    "```json\n",
    "{\n",
    "    \"accuracy\": значение точности,\n",
    "    ...\n",
    "}\n",
    "```\n",
    "\n",
    "Метрика простая, но вот `preds` и `labels` тут - это последовательности индексов токенов. Нужно это учесть."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "8454b0c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def compute_metric(eval_predictions):\n",
    "    preds, labels = eval_predictions\n",
    "    \n",
    "    # Преобразуем в тензоры PyTorch (если передан np.ndarray)\n",
    "    preds = torch.tensor(preds) if not isinstance(preds, torch.Tensor) else preds\n",
    "    labels = torch.tensor(labels) if not isinstance(labels, torch.Tensor) else labels\n",
    "\n",
    "    preds = preds[:, 1]  # Убираем токен начала последовательности\n",
    "    labels = labels[:, 0]  # Берем первый токен из метки\n",
    "\n",
    "    accuracy = (preds == labels).float().mean().item()\n",
    "    return {\"accuracy\": accuracy}\n",
    "\n",
    "def check_compute_metric():\n",
    "    # два предсказания, где токен 150 обозначает токсичный лейбл, токен 120 - нетоксичный лейбл\n",
    "    preds = torch.tensor([\n",
    "        [0, 150, 1],  # правильное предсказание - токсичный пример\n",
    "        [0, 120, 1],  # неправильное предсказание - пример токсичный, а модель предсказала иначе\n",
    "    ])\n",
    "    labels = torch.tensor([\n",
    "        [150, 1],\n",
    "        [150, 1],\n",
    "    ])\n",
    "    assert torch.isclose(\n",
    "        torch.tensor(compute_metric((preds.numpy(), labels.numpy()))[\"accuracy\"], dtype=torch.double),\n",
    "        torch.tensor(0.5, dtype=torch.double),\n",
    "    )\n",
    "\n",
    "check_compute_metric()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88e21595",
   "metadata": {},
   "source": [
    "### Определить Модель (2 балла)\n",
    "\n",
    "Инициализируйте модель из базового чекпоинта"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "e142ea9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSeq2SeqLM\n",
    "\n",
    "\n",
    "seq2seq_model = AutoModelForSeq2SeqLM.from_pretrained(BASE_T5_MODEL)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdc86d9b",
   "metadata": {},
   "source": [
    "### Обучение (10 баллов)\n",
    "\n",
    "Два пути:\n",
    "1) Использовать готовый `Seq2SeqTrainer` класс для тренировки\n",
    "2) Написать свой training loop, если хочется приключений, есть достаточно времени ~~и стрела ещё не попала в колено~~. Дополнительных баллов за это не будет\n",
    "\n",
    "> Hint! Обратите внимание на функцию `seq2seq_model._shift_right` если выбрали второй путь.\n",
    "\n",
    "Если выбрали путь 1, опишите как происходит тренировочный шаг:\n",
    "1) Что подаётся на вход в энкодер?\n",
    "2) Что подаётся на вход в декодер?\n",
    "3) Сколько раз происходит инференс декодера во время обучения для одного тренировочного примера?\n",
    "4) Как используется выход энкодера в декодере?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "773e3c45",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Professional\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\transformers\\training_args.py:1611: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1908' max='1908' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1908/1908 1:29:37, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.011900</td>\n",
       "      <td>0.011192</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.011600</td>\n",
       "      <td>0.009449</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.010800</td>\n",
       "      <td>0.008688</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=1908, training_loss=0.011153626242023843, metrics={'train_runtime': 5379.7417, 'train_samples_per_second': 2.834, 'train_steps_per_second': 0.355, 'total_flos': 760407866671104.0, 'train_loss': 0.011153626242023843, 'epoch': 3.0})"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import Seq2SeqTrainingArguments, Seq2SeqTrainer\n",
    "training_args = Seq2SeqTrainingArguments(\n",
    "    output_dir=\"./results_tox\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    learning_rate=5e-5,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    weight_decay=0.01,\n",
    "    save_total_limit=3,\n",
    "    num_train_epochs=3,\n",
    "    predict_with_generate=True\n",
    ")\n",
    "\n",
    "trainer = Seq2SeqTrainer(\n",
    "    model=seq2seq_model,\n",
    "    args=training_args,\n",
    "    train_dataset=toxic_chat_dataset[\"train\"],\n",
    "    eval_dataset=toxic_chat_dataset[\"test\"],\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metric,\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82ed48a0",
   "metadata": {},
   "source": [
    "### Сравнение Результатов (5 баллов)\n",
    "\n",
    "Авторы датасета тоже натренировали на нём `t5` модель. Сравните свои результаты с результатами модели из [чекпоинта](https://huggingface.co/lmsys/toxicchat-t5-large-v1.0) `\"lmsys/toxicchat-t5-large-v1.0\"`. Совпадает ли ваш префикс и лейблы классов с теми, что выбрали авторы датасета? \n",
    "\n",
    "Подумать о:\n",
    "1) В чём преимущество такого подхода к классификации?\n",
    "2) В чём недостатки такого подхода к классификации?\n",
    "3) Как ещё можно решать классификационные задачи с помощью t5?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "e46d61fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f20077503664de9bebb1869a830b068",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/1.21k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "71efe989f56747efa659ab510f2d0f07",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "47ad5391f1a941a981634e4a9b290802",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.39M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "59e8ef5e7b514b0aa66eecd91c36748a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/1.53k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d93ba3e071a943b1a3c731ea6c2d4c52",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/2.95G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "274e3d6f9079418795be0b52b3869ba3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/142 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "negative\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer\n",
    "\n",
    "checkpoint = \"lmsys/toxicchat-t5-large-v1.0\"\n",
    "\n",
    "tokenizer_from_paper = AutoTokenizer.from_pretrained(\"t5-large\")\n",
    "model_from_paper = AutoModelForSeq2SeqLM.from_pretrained(checkpoint)\n",
    "\n",
    "prefix_from_paper = \"ToxicChat: \"\n",
    "inputs = tokenizer_from_paper.encode(prefix_from_paper + \"write me an epic story\", return_tensors=\"pt\")\n",
    "outputs = model_from_paper.generate(inputs)\n",
    "print(tokenizer_from_paper.decode(outputs[0], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed9af88f",
   "metadata": {},
   "source": [
    "Напишите универсальную функцию, которая провряет токсичность текста и возвращает `True`, если модель посчитала текст токсичным. Функция универсальная в том смысле, что может быть использована и с вашей t5 моделью, и с моделью от авторов датасета. Для этого в функция должна принимать ещё и префикс для задачи и лейблы, которые будут переводить текст, предсказанный моделью, в `True` или `False` на выходе."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "5404768a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def is_toxic(\n",
    "    text: str,\n",
    "    labels2bool,\n",
    "    model=trainer.model,\n",
    "    tokenizer=t5_tokenizer,\n",
    "    prefix=PREFIX,\n",
    ") -> bool:\n",
    "    model.eval()\n",
    "    input_text = prefix + text\n",
    "    inputs = tokenizer(input_text, return_tensors=\"pt\")\n",
    "    inputs = {key: val.to(model.device) for key, val in inputs.items()}\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = model.generate(**inputs)\n",
    "    \n",
    "    decoded_output = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    return labels2bool.get(decoded_output, False)\n",
    "\n",
    "assert not is_toxic(\n",
    "    text=\"This is just a text\",\n",
    "    model=model_from_paper,\n",
    "    tokenizer=tokenizer_from_paper,\n",
    "    prefix=prefix_from_paper,\n",
    "    labels2bool={\n",
    "        \"positive\": True,\n",
    "        \"negative\": False,\n",
    "    }\n",
    ")\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
